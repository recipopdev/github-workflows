name: Deploy Service
on:
  workflow_call:
    inputs:
      service:
        required: true
        type: string
      account:
        required: true
        type: string
      commit_hash:
        type: string
      sonar_scan_path:
        type: string
      api_test_env_vars:
        type: string
      database_migration_dockerfile:
        type: string
      dotnet_sonar_scan:
        type: boolean
      self_hosted:
        type: boolean
      pre_script:
        type: string
      track_deployment:
        type: boolean
        default: true
      working_directory:
        type: string
        default: "."
      lambda_deployment:
        type: boolean
        default: false
      node_cache:
        type: string
        default: ""
    secrets:
      aws_key:
        required: true
      aws_secret:
        required: true
      region:
        required: true
      sonar_token:
      api_test_secret_vars:

env:
  AWS_ACCESS_KEY_ID: ${{ secrets.aws_key }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.aws_secret }}
  AWS_DEFAULT_REGION: ${{ secrets.region }}
  DEPLOY_SERVICE: ${{ inputs.service }}
  DEPLOY_ACCOUNT: ${{ inputs.account }}
  API_TEST_ENV_VARS: ${{ inputs.api_test_env_vars }}
  API_TEST_SECRET_VARS: ${{ secrets.api_test_secret_vars }}
  SONAR_SCAN_PATH: ${{ inputs.sonar_scan_path }}
  SONAR_TOKEN: ${{ secrets.sonar_token }}
  DATABASE_MIGRATION_DOCKERFILE: ${{ inputs.database_migration_dockerfile }}
  TF_VAR_commit_sha: ${{ github.sha }}${{ github.run_attempt }}
  TF_VAR_github_token: ${{ secrets.GITHUB_TOKEN }}
jobs:
  deploy-service:
    runs-on: ${{ (inputs.self_hosted && 'self-hosted') || 'ubuntu-20.04' }}
    steps:
      - name: Preparing working directory on self hosted runner
        if: ${{ inputs.self_hosted }}
        id: prep
        run: sudo chown -R $USER:$USER /home/ubuntu/actions-runner/_work/$(echo "${{ github.repository }}" | sed "s|${{ github.repository_owner }}/||")

      - uses: actions/checkout@v2
      - uses: actions/checkout@v2
        with:
          repository: recipopdev/github-workflows
          path: github-workflows

      - uses: actions/setup-node@v3
        if: ${{ inputs.node_cache != '' }}
        id: node-cache
        with:
          node-version: 20
          cache: ${{ inputs.node_cache }}

      - name: Copy deployment scripts
        id: deployment-scripts
        run: |
          cp github-workflows/scripts/python/*.py ${{ inputs.working_directory }}/deploy/
          cp github-workflows/scripts/linux/*.sh ${{ inputs.working_directory }}/deploy/

      - name: Install dependencies
        id: dependencies
        run: pip3 install --user Jinja2 PyYAML boto3 packaging prometheus_client
        working-directory: ${{ inputs.working_directory }}/deploy/

      - name: Report Running Pipeline
        id: pipeline-reporting-running
        run: python3 pipeline_reporting.py --service $DEPLOY_SERVICE --environment $DEPLOY_ACCOUNT --running
        working-directory: ${{ inputs.working_directory }}/deploy/

      - name: Fetch version & iterate version
        if: inputs.lambda_deployment == false
        id: iterate-version
        run: |
          python3 versioning.py --service $DEPLOY_SERVICE --fetch
          if [[ $DEPLOY_ACCOUNT == "uat" ]]; then
            npm version patch
          fi
          if [[ $DEPLOY_ACCOUNT == "production" ]]; then
            npm version minor
          fi
        working-directory: ${{ inputs.working_directory }}/deploy/

      - name: Generate ECR token
        id: token
        run: python3 ecr_authenticate.py --environment $DEPLOY_ACCOUNT
        working-directory: ${{ inputs.working_directory }}/deploy/

      - name: Bootstrap terraform files
        id: bootstrap
        run: python3 bootstrap.py;
        working-directory: ${{ inputs.working_directory }}/deploy/

      - name: Prepare deployment files
        id: prepare
        run: |
          cp ${{ inputs.working_directory }}/deploy/*.tf* ${{ inputs.working_directory }}/
          cp ${{ inputs.working_directory }}/deploy/package.json ${{ inputs.working_directory }}/ 2>/dev/null || true

      - uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.1.4
          terraform_wrapper: false

      - name: Terraform fmt
        id: fmt
        run: terraform fmt -check -diff
        working-directory: ${{ inputs.working_directory }}

      - name: Terraform Init
        id: init
        run: terraform init -input=false
        working-directory: ${{ inputs.working_directory }}

      - name: Pre Script
        if: ${{ inputs.pre_script != '' }}
        id: pre-script
        run: bash ${{ inputs.pre_script }}
        working-directory: ${{ inputs.working_directory }}

      - name: Terraform Validate
        id: validate
        run: terraform validate -no-color
        working-directory: ${{ inputs.working_directory }}

      - name: Select Workspace
        id: workspace
        run: |
          if [[ $DEPLOY_ACCOUNT == "uat" ]]; then
            terraform workspace select uat
          fi
          if [[ $DEPLOY_ACCOUNT == "production" ]]; then
            terraform workspace select prod
          fi
        working-directory: ${{ inputs.working_directory }}

      - name: Run Database Migration
        if: ${{ inputs.database_migration_dockerfile != '' }}
        id: database-migration
        run: |
          SHORT_ACCOUNT_NAME=dev
          if [[ $DEPLOY_ACCOUNT == "uat" ]]; then
            SHORT_ACCOUNT_NAME=uat
          fi
          if [[ $DEPLOY_ACCOUNT == "production" ]]; then
            SHORT_ACCOUNT_NAME=prod
          fi
          source deploy/switch_role.sh $(echo "."$DEPLOY_ACCOUNT"_account")
          docker build \
            --build-arg AWS_REGION=$AWS_DEFAULT_REGION \
            --build-arg AWS_ACCESS_KEY_ID=$SWITCHED_AWS_ACCESS_KEY_ID \
            --build-arg AWS_SECRET_ACCESS_KEY=$SWITCHED_AWS_SECRET_ACCESS_KEY \
            --build-arg AWS_SESSION_TOKEN=$SWITCHED_AWS_SESSION_TOKEN \
            --build-arg DEPLOY_ACCOUNT=$SHORT_ACCOUNT_NAME \
            -f $DATABASE_MIGRATION_DOCKERFILE \
            .
        working-directory: ${{ inputs.working_directory }}

      - name: Terraform Apply
        id: apply
        run: terraform apply -auto-approve -input=false
        working-directory: ${{ inputs.working_directory }}

      - name: Commit version
        if: inputs.lambda_deployment == false
        id: commit-version
        run: |
          if [[ $DEPLOY_ACCOUNT != "development" ]]; then
            python3 versioning.py --service $DEPLOY_SERVICE --save
          fi
        working-directory: ${{ inputs.working_directory }}/deploy/

      - name: Terraform Confirm
        id: confirm
        run: terraform plan -input=false -detailed-exitcode
        working-directory: ${{ inputs.working_directory }}

      - name: Scan Docker Image
        if: inputs.lambda_deployment == false
        id: image-scan
        run: python3 image_scan.py --environment $DEPLOY_ACCOUNT --service $DEPLOY_SERVICE
        working-directory: ${{ inputs.working_directory }}/deploy/

      - name: Run Sonar Scanner
        if: ${{ inputs.sonar_scan_path != '' }}
        id: sonar-scan
        run: docker run -e SONAR_HOST_URL="https://sonarqube.mgmt.adimo.co" -e SONAR_LOGIN=$SONAR_TOKEN -v "$(pwd)/"$SONAR_SCAN_PATH":/usr/src" sonarsource/sonar-scanner-cli -Dsonar.projectKey=$DEPLOY_SERVICE
        working-directory: ${{ inputs.working_directory }}

      - name: Run DotNet Sonar Scanner Self Hosted
        if: ${{ inputs.dotnet_sonar_scan }}
        id: dotnet-sonar-scan
        uses: calxus/action-sonarqube-dotnet@1.0.9
        with:
          sonarProjectKey: $DEPLOY_SERVICE
          sonarHostname: "https://sonarqube.mgmt.adimo.co"
          nugetSource: "http://nuget.services.internal.mgmt.adimo.co/v3/index.json"

      - name: Track deployment rollout
        if: inputs.track_deployment == true
        id: track-rollout
        run: python3 track_deployment.py --service $DEPLOY_SERVICE --environment $DEPLOY_ACCOUNT
        working-directory: ${{ inputs.working_directory }}/deploy/

      - name: Combining API Test Environment Variables
        if: |
          inputs.api_test_env_vars != '' &&
          inputs.track_deployment == true
        id: combine-api-vars
        run: |
          if [[ $API_TEST_SECRET_VARS != "" ]]; then
            API_TEST_VARS=$(echo -e "$API_TEST_ENV_VARS\n$API_TEST_SECRET_VARS" | jq -s 'add' --raw-output)
          else
            API_TEST_VARS=$(echo -e "$API_TEST_ENV_VARS")
          fi
          echo "::set-output name=api-test-vars::$(echo $API_TEST_VARS)"
        working-directory: ${{ inputs.working_directory }}

      - name: Run API Tests
        if: |
          inputs.api_test_env_vars != '' &&
          inputs.track_deployment == true
        id: run-tests
        uses: matt-ball/newman-action@master
        with:
          collection: ${{ inputs.working_directory }}/deploy/tests/tests.json
          envVar: ${{ steps.combine-api-vars.outputs.api-test-vars }}

      - name: Report Successful Pipeline
        id: pipeline-reporting-success
        run: python3 pipeline_reporting.py --service $DEPLOY_SERVICE --environment $DEPLOY_ACCOUNT --success
        working-directory: ${{ inputs.working_directory }}/deploy/

      - name: Report Failed Pipeline
        if: cancelled() || failure()
        id: pipeline-reporting-failure
        run: python3 pipeline_reporting.py --service $DEPLOY_SERVICE --environment $DEPLOY_ACCOUNT --failure
        working-directory: ${{ inputs.working_directory }}/deploy/
